# greenflash_llm_project
Conduct research into LLMs and develop models for detecting toxicity, bias and other metrics
